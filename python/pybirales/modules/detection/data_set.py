import logging as log
import os
import pickle
import time
import numpy as np

from datetime import datetime
from multiprocessing.dummy import Pool as ThreadPool
from pybirales.modules.detection.beam import Beam
from pybirales.base import settings


class DataSet:
    """
    The DataSet class encapsulates the logic for reading and creating the beam data from the data set
    that was generated by the PyBirales Backend
    """
    config_ext = '.dat.pkl'
    data_set_ext = '.dat'

    def __init__(self, observation_name, data_set_name, n_beams):
        """
        Initialise the Data Set object

        :param observation_name:
        :param data_set_name:
        :param n_beams:
        :return:
        """
        self.observation_name = observation_name
        self.name = data_set_name
        self.id = observation_name + '.' + self.name
        self.data_file_path = self._get_data_file_path(self.observation_name, data_set_name)
        self.config_file_path = self._get_config_file_path(self.observation_name, data_set_name)

        self._init_visualisation_directory(observation_name, data_set_name)

        self.config = self._init_data_set_config(self.config_file_path)
        self.n_beams = int(n_beams) or self.config['nbeams']
        self.n_channels = self.config['nchans']
        self.tx = self.config['transmitter_frequency']

        # Read the data set data
        self.data = self._read_data_set(self.data_file_path, self.n_beams, self.n_channels)

    def _read_data_set(self, data_set_file_path, n_beams, n_channels):
        """
        Read beam data from the data_set file associated with this observation

        :param n_beams: The number of beams
        :param n_channels: The number of channels
        :return: The processed beam data
        """
        log.info('Reading data set at %s', data_set_file_path)
        start = time.time()
        if os.path.isfile(data_set_file_path):
            data = np.fromfile(data_set_file_path, dtype=np.dtype('f'))
            limit = n_beams / float(self.config['nbeams']) * len(data)
            data = data[:int(limit)]
            n_samples = int(len(data) /
                            (n_beams * n_channels))
            data = np.reshape(data, (n_samples, n_channels, n_beams))

            log.info('Data set data loaded in %s s', DataSet._time_taken(start))
            log.info('Read %s samples (%s s), %s channels, %s beams', n_samples,
                     round(self.config['sampling_rate'] * n_samples, 2), n_channels, n_beams)

            return data

        raise IOError('Data set was not found at ' + data_set_file_path)

    def create_beams(self, n_beams):
        """
        Create and return a list of Beam objects from the beam data.

        :param n_beams: Number of beams to create from the data_set
        :return: A list of Beams extracted from the data set data
        """

        # Initialise thread pool
        pool = ThreadPool(32)

        # Create the iterable
        n_beams = range(0, n_beams)

        # Collect the beam data processed by N threads
        beams = pool.map(self.create_beam, n_beams)

        pool.close()
        pool.join()

        return beams

    def create_beam(self, n_beam):
        log.debug('Generating beam %s from data set %s', n_beam, self.name)
        beam = Beam(beam_id=n_beam,
                    dec=0.0,
                    ra=0.0,
                    ha=0.0,
                    top_frequency=0.0,
                    frequency_offset=0.0,
                    data_set=self, beam_data=self.data)
        return beam

    @staticmethod
    def _init_data_set_config(config_file_path):
        """
        Configure this observation with the settings of the pickle file in the data_set
        :param config_file_path: The file path of where the data set configuration is located
        :return:
        """

        if os.path.isfile(config_file_path):
            data_set_config = pickle.load(open(config_file_path, "rb"))
            # todo - change these or remove
            # todo - validate settings read from pickle
            data_set_config['n_sub_channels'] = data_set_config['nchans']
            data_set_config['sampling_rate'] = data_set_config['sampling_time']
            data_set_config['f_ch1'] = data_set_config['start_center_frequency']
            data_set_config['timestamp'] = 1464250387401        # Timestamp in ms
            data_set_config['human_timestamp'] = DataSet._get_human_timestamp(data_set_config['timestamp'])

            if 'channel_bandwidth' in data_set_config:
                data_set_config['f_off'] = data_set_config['channel_bandwidth']
            elif 'bandwidth' in data_set_config:
                data_set_config['f_off'] = data_set_config['bandwidth']
            else:
                raise Exception('Data configuration is incorrect')

            return data_set_config

        raise IOError('Config file was not found at ' + config_file_path)

    @staticmethod
    def _get_human_timestamp(timestamp):
        """
        Return a human readable timestamp (including the timezone offset)

        :param timestamp: The unix time stamp (in milli seconds)
        :return:
        """
        value = datetime.utcfromtimestamp(timestamp / 1000.)
        return value.strftime('%Y-%m-%d %H:%M:%S') + ' UTC+00:00'

    @staticmethod
    def _time_taken(start):
        """
        Return the time taken between now and a start time

        :param start: The time from which to subtract the current time
        :return:
        """
        time_taken = time.time() - start
        return round(time_taken, 2)

    @staticmethod
    def _init_visualisation_directory(observation_name, data_set_name):
        file_path = os.path.join(settings.monitoring.file_path, observation_name, data_set_name)
        if not os.path.exists(file_path):
            os.makedirs(file_path)

    def _get_data_file_path(self, observation_name, data_set_name):
        """
        Get the data file path for the specified observation and data set

        :param observation_name:
        :param data_set_name:
        :return:
        """
        base_path = settings.io.data_file_path
        return os.path.join(base_path, observation_name, data_set_name, data_set_name + self.data_set_ext)

    def _get_config_file_path(self, observation_name, data_set_name):
        """
        Get the configuration file path for the specified observation and data set

        :param observation_name:
        :param data_set_name:
        :return:
        """
        base_path = settings.io.data_file_path
        return os.path.join(base_path, observation_name, data_set_name, data_set_name + self.config_ext)

    def __iter__(self):
        """
        Get a dict representation of this data set object

        :return:
        """
        yield 'name', self.name
        yield 'observation', self.observation_name
        yield 'n_channels', self.n_channels
        yield 'n_beams', self.n_beams
        yield 'tx', self.tx
        yield 'created_at', datetime.now()
        yield 'config', self.config


class DataSetBlob:
    """
    The DataSet class encapsulates the logic for reading and creating the beam data from the data set
    that was generated by the PyBirales Backend

    Class instantiates data sets objects from Channelized blobs
    TODO - replace this with just a blob (this is an extra class that can be removed eventually)
    """
    config_ext = '.dat.pkl'
    data_set_ext = '.dat'

    def __init__(self, observation_name, data_set_name, n_beams):
        """
        Initialise the Data Set object

        :param observation_name:
        :param data_set_name:
        :param n_beams:
        :return:
        """
        self.observation_name = observation_name
        self.name = data_set_name
        self.id = observation_name + '.' + self.name
        self.data_file_path = self._get_data_file_path(self.observation_name, data_set_name)
        self.config_file_path = self._get_config_file_path(self.observation_name, data_set_name)

        self._init_visualisation_directory(observation_name, data_set_name)

        self.config = self._init_data_set_config(self.config_file_path)
        self.n_beams = int(n_beams) or self.config['nbeams']
        self.n_channels = self.config['nchans']
        self.tx = self.config['transmitter_frequency']

        # Read the data set data
        self.data = self._read_data_set(self.data_file_path, self.n_beams, self.n_channels)

    def _read_data_set(self, data_set_file_path, n_beams, n_channels):
        """
        Read beam data from the data_set file associated with this observation

        :param n_beams: The number of beams
        :param n_channels: The number of channels
        :return: The processed beam data
        """
        log.info('Reading data set at %s', data_set_file_path)
        start = time.time()
        if os.path.isfile(data_set_file_path):
            data = np.fromfile(data_set_file_path, dtype=np.dtype('f'))
            limit = n_beams / float(self.config['nbeams']) * len(data)
            data = data[:int(limit)]
            n_samples = int(len(data) /
                            (n_beams * n_channels))
            data = np.reshape(data, (n_samples, n_channels, n_beams))

            log.info('Data set data loaded in %s s', DataSet._time_taken(start))
            log.info('Read %s samples (%s s), %s channels, %s beams', n_samples,
                     round(self.config['sampling_rate'] * n_samples, 2), n_channels, n_beams)

            return data

        raise IOError('Data set was not found at ' + data_set_file_path)

    def create_beams(self, n_beams):
        """
        Create and return a list of Beam objects from the beam data.

        :param n_beams: Number of beams to create from the data_set
        :return: A list of Beams extracted from the data set data
        """

        # Initialise thread pool
        pool = ThreadPool(32)

        # Create the iterable
        n_beams = range(0, n_beams)

        # Collect the beam data processed by N threads
        beams = pool.map(self.create_beam, n_beams)

        pool.close()
        pool.join()

        return beams

    def create_beam(self, n_beam):
        log.debug('Generating beam %s from data set %s', n_beam, self.name)
        beam = Beam(beam_id=n_beam,
                    dec=0.0,
                    ra=0.0,
                    ha=0.0,
                    top_frequency=0.0,
                    frequency_offset=0.0,
                    data_set=self, beam_data=self.data)
        return beam

    @staticmethod
    def _init_data_set_config(config_file_path):
        """
        Configure this observation with the settings of the pickle file in the data_set
        :param config_file_path: The file path of where the data set configuration is located
        :return:
        """

        if os.path.isfile(config_file_path):
            data_set_config = pickle.load(open(config_file_path, "rb"))
            # todo - change these or remove
            # todo - validate settings read from pickle
            data_set_config['n_sub_channels'] = data_set_config['nchans']
            data_set_config['sampling_rate'] = data_set_config['sampling_time']
            data_set_config['f_ch1'] = data_set_config['start_center_frequency']
            data_set_config['timestamp'] = 1464250387401        # Timestamp in ms
            data_set_config['human_timestamp'] = DataSet._get_human_timestamp(data_set_config['timestamp'])

            if 'channel_bandwidth' in data_set_config:
                data_set_config['f_off'] = data_set_config['channel_bandwidth']
            elif 'bandwidth' in data_set_config:
                data_set_config['f_off'] = data_set_config['bandwidth']
            else:
                raise Exception('Data configuration is incorrect')

            return data_set_config

        raise IOError('Config file was not found at ' + config_file_path)

    @staticmethod
    def _get_human_timestamp(timestamp):
        """
        Return a human readable timestamp (including the timezone offset)

        :param timestamp: The unix time stamp (in milli seconds)
        :return:
        """
        value = datetime.utcfromtimestamp(timestamp / 1000.)
        return value.strftime('%Y-%m-%d %H:%M:%S') + ' UTC+00:00'

    @staticmethod
    def _time_taken(start):
        """
        Return the time taken between now and a start time

        :param start: The time from which to subtract the current time
        :return:
        """
        time_taken = time.time() - start
        return round(time_taken, 2)

    @staticmethod
    def _init_visualisation_directory(observation_name, data_set_name):
        file_path = os.path.join(settings.monitoring.file_path, observation_name, data_set_name)
        if not os.path.exists(file_path):
            os.makedirs(file_path)

    def _get_data_file_path(self, observation_name, data_set_name):
        """
        Get the data file path for the specified observation and data set

        :param observation_name:
        :param data_set_name:
        :return:
        """
        base_path = settings.io.data_file_path
        return os.path.join(base_path, observation_name, data_set_name, data_set_name + self.data_set_ext)

    def _get_config_file_path(self, observation_name, data_set_name):
        """
        Get the configuration file path for the specified observation and data set

        :param observation_name:
        :param data_set_name:
        :return:
        """
        base_path = settings.io.data_file_path
        return os.path.join(base_path, observation_name, data_set_name, data_set_name + self.config_ext)

    def __iter__(self):
        """
        Get a dict representation of this data set object

        :return:
        """
        yield 'name', self.name
        yield 'observation', self.observation_name
        yield 'n_channels', self.n_channels
        yield 'n_beams', self.n_beams
        yield 'tx', self.tx
        yield 'created_at', datetime.now()
        yield 'config', self.config